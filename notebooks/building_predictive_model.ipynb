{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data_path = os.path.join(os.path.pardir,'data','processed')\n",
    "train_file_path = os.path.join(processed_data_path,'train.csv')\n",
    "test_file_path = os.path.join(processed_data_path,'test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df=pd.read_csv(train_file_path,index_col='PassengerId')\n",
    "test_df=pd.read_csv(test_file_path,index_col='PassengerId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 891 entries, 1 to 891\n",
      "Data columns (total 33 columns):\n",
      "Survived              891 non-null int64\n",
      "Age                   891 non-null float64\n",
      "Fare                  891 non-null float64\n",
      "FamilySize            891 non-null int64\n",
      "IsMother              891 non-null int64\n",
      "IsMale                891 non-null int64\n",
      "Deck_A                891 non-null int64\n",
      "Deck_B                891 non-null int64\n",
      "Deck_C                891 non-null int64\n",
      "Deck_D                891 non-null int64\n",
      "Deck_E                891 non-null int64\n",
      "Deck_F                891 non-null int64\n",
      "Deck_G                891 non-null int64\n",
      "Deck_Z                891 non-null int64\n",
      "Pclass_1              891 non-null int64\n",
      "Pclass_2              891 non-null int64\n",
      "Pclass_3              891 non-null int64\n",
      "Title_Lady            891 non-null int64\n",
      "Title_Master          891 non-null int64\n",
      "Title_Miss            891 non-null int64\n",
      "Title_Mr              891 non-null int64\n",
      "Title_Mrs             891 non-null int64\n",
      "Title_Officer         891 non-null int64\n",
      "Title_Sir             891 non-null int64\n",
      "Fare_Bin_very_low     891 non-null int64\n",
      "Fare_Bin_low          891 non-null int64\n",
      "Fare_Bin_high         891 non-null int64\n",
      "Fare_Bin_very_high    891 non-null int64\n",
      "Embarked_C            891 non-null int64\n",
      "Embarked_Q            891 non-null int64\n",
      "Embarked_S            891 non-null int64\n",
      "AgeState_Adult        891 non-null int64\n",
      "AgeState_Child        891 non-null int64\n",
      "dtypes: float64(2), int64(31)\n",
      "memory usage: 236.7 KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 418 entries, 892 to 1309\n",
      "Data columns (total 32 columns):\n",
      "Age                   418 non-null float64\n",
      "Fare                  418 non-null float64\n",
      "FamilySize            418 non-null int64\n",
      "IsMother              418 non-null int64\n",
      "IsMale                418 non-null int64\n",
      "Deck_A                418 non-null int64\n",
      "Deck_B                418 non-null int64\n",
      "Deck_C                418 non-null int64\n",
      "Deck_D                418 non-null int64\n",
      "Deck_E                418 non-null int64\n",
      "Deck_F                418 non-null int64\n",
      "Deck_G                418 non-null int64\n",
      "Deck_Z                418 non-null int64\n",
      "Pclass_1              418 non-null int64\n",
      "Pclass_2              418 non-null int64\n",
      "Pclass_3              418 non-null int64\n",
      "Title_Lady            418 non-null int64\n",
      "Title_Master          418 non-null int64\n",
      "Title_Miss            418 non-null int64\n",
      "Title_Mr              418 non-null int64\n",
      "Title_Mrs             418 non-null int64\n",
      "Title_Officer         418 non-null int64\n",
      "Title_Sir             418 non-null int64\n",
      "Fare_Bin_very_low     418 non-null int64\n",
      "Fare_Bin_low          418 non-null int64\n",
      "Fare_Bin_high         418 non-null int64\n",
      "Fare_Bin_very_high    418 non-null int64\n",
      "Embarked_C            418 non-null int64\n",
      "Embarked_Q            418 non-null int64\n",
      "Embarked_S            418 non-null int64\n",
      "AgeState_Adult        418 non-null int64\n",
      "AgeState_Child        418 non-null int64\n",
      "dtypes: float64(2), int64(30)\n",
      "memory usage: 107.8 KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.info(),test_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "#now we prepare data:\n",
    "\n",
    "X= train_df.loc[:,'Age':].as_matrix().astype('float')\n",
    "y=train_df['Survived'].ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 32) (891,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape,y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(712, 32) (179, 32)\n",
      "(712,) (179,)\n"
     ]
    }
   ],
   "source": [
    "# testing train split will be used for the training model:\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=0)\n",
    "print(X_train.shape,X_test.shape)\n",
    "print(y_train.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Survival in Train:  0.383\n",
      "Mean Survival in Test:  0.385\n"
     ]
    }
   ],
   "source": [
    "print('Mean Survival in Train: {0: .3f}'.format(np.mean(y_train)))\n",
    "print('Mean Survival in Test: {0: .3f}'.format(np.mean(y_test)))\n",
    "# so we can see that the mean is approx to 38%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scikit-Learning\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.19.1'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing BaseLine Model for 1st Kaggle Submission\n",
    "from sklearn.dummy import DummyClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DummyClassifier(constant=None, random_state=0, strategy='most_frequent')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prepare model\n",
    "dummy_model = DummyClassifier(strategy='most_frequent',random_state=0)\n",
    "# Train the model\n",
    "dummy_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for Baseline Model :  0.61\n",
      "confusion matrix for baseline model: \n",
      " [[110   0]\n",
      " [ 69   0]]\n",
      "Accuracy for Baseline Model :  0.61\n",
      "Precision for BaseLine Model:  0.00\n",
      "Recall Score for BaseLine model is:  0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print('Score for Baseline Model : {0: .2f}'.format(dummy_model.score(X_test,y_test)))\n",
    "# This score is same for Accuracy too\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score\n",
    "# Confusion Matrix\n",
    "print('confusion matrix for baseline model: \\n {0}'.format(confusion_matrix(y_test, dummy_model.predict(X_test))))\n",
    "# Accuracy for Model\n",
    "print('Accuracy for Baseline Model : {0: .2f}'.format(accuracy_score(y_test,dummy_model.predict(X_test))))\n",
    "#precision\n",
    "print('Precision for BaseLine Model: {0: .2f}'.format(precision_score(y_test,dummy_model.predict(X_test))))\n",
    "#recall Score\n",
    "print('Recall Score for BaseLine model is: {0: .2f}'.format(recall_score(y_test,dummy_model.predict(X_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "# Now we will make Kaggle Submission\n",
    "# 1. Convert it to the Matrix\n",
    "test_X = test_df.as_matrix().astype('float')\n",
    "# 2. Get predictions\n",
    "predictions = dummy_model.predict(test_X)\n",
    "# 3. Create Submission DATA FRAME, mapping the values with Passenger ID's\n",
    "df_submission = pd.DataFrame({'PassengerId': test_df.index,'Survived':predictions})\n",
    "# 4. Check the table\n",
    "df_submission.head()\n",
    "# 5. Create Paths\n",
    "submission_data_path=os.path.join(os.path.pardir,'data','external')\n",
    "submission_file_path=os.path.join(submission_data_path,'baseline_model.csv')\n",
    "df_submission.to_csv(submission_file_path,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the function for the Above work done:\n",
    "def get_submission_file(model,filename):\n",
    "    test_X = test_df.as_matrix().astype('float')\n",
    "    predictions = model.predict(test_X)\n",
    "    df_sub = pd.DataFrame({'PassengerId': test_df.index,'Survived':predictions})\n",
    "    submission_data_path = os.path.join(os.path.pardir,'data','external')\n",
    "    submission_file_path = os.path.join(submission_data_path,filename)\n",
    "    df_sub.to_csv(submission_file_path,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "# get the file\n",
    "get_submission_file(dummy_model,'baseline_model.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score :  0.83\n",
      "Accuracy for LR:  0.83\n",
      "confusion matrix for logistic regression - version 1: \n",
      " [[95 15]\n",
      " [15 54]]\n",
      "precision for logistic regression - version 1 : 0.78\n",
      "recall for logistic regression - version 1 : 0.78\n"
     ]
    }
   ],
   "source": [
    "# Now we will use Logistic Regression Model to improve over our BaseLine model result\n",
    "#import func\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "#create Model\n",
    "model_logistic_reg = LogisticRegression(random_state=0)\n",
    "#train model\n",
    "model_logistic_reg.fit(X_train,y_train)\n",
    "\n",
    "#evaluate this model\n",
    "print('Score : {0: .2f}'.format(model_logistic_reg.score(X_test,y_test)))\n",
    "# now look on performance metrics:\n",
    "#1. Accuracy:\n",
    "print('Accuracy for LR: {0: .2f}'.format(accuracy_score(y_test,model_logistic_reg.predict(X_test))))\n",
    "#2. confusion matrix\n",
    "print('confusion matrix for logistic regression - version 1: \\n {0}'.format(confusion_matrix(y_test, model_logistic_reg.predict(X_test))))\n",
    "#3. precision \n",
    "print('precision for logistic regression - version 1 : {0:.2f}'.format(precision_score(y_test, model_logistic_reg.predict(X_test))))\n",
    "#4. Recall \n",
    "print('recall for logistic regression - version 1 : {0:.2f}'.format(recall_score(y_test, model_logistic_reg.predict(X_test))))\n",
    "\n",
    "# Here the score is 83% and in BaseLine was 61%......Hence we can see the improvement significantly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.02840734,  0.00455631, -0.50017004,  0.61922838, -0.81414743,\n",
       "         0.12823264, -0.17253859, -0.39355488,  0.52215008,  1.09939125,\n",
       "         0.40346551, -0.18369316, -0.30021028,  0.96558544,  0.48281794,\n",
       "        -0.3451608 ,  0.28258585,  1.21850069,  0.56334183, -1.44612507,\n",
       "         1.07146232, -0.11345497, -0.47306807,  0.16297326,  0.24746349,\n",
       "         0.27998252,  0.4128233 ,  0.49202884,  0.46214499,  0.14906873,\n",
       "         0.37253571,  0.73070686]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_logistic_reg.coef_\n",
    "#These are weights/parameters for the model(b0 & b1)\n",
    "# y=b0+b1*age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "# Kaggle Submission using Logistic regression\n",
    "get_submission_file(model_logistic_reg,'logistic_regression_model.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
